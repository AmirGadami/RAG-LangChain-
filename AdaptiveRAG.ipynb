{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "ac6f903d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from typing import Literal\n",
    "from pprint import pprint\n",
    "from langchain import hub\n",
    "from typing import Literal,List\n",
    "from typing_extensions import TypedDict\n",
    "from langchain_cohere import CohereEmbeddings, ChatCohere\n",
    "from langgraph.graph import END,START,StateGraph\n",
    "from langchain.schema import Document\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings,ChatOpenAI\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.pydantic_v1 import Field,BaseModel\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "\n",
    "\n",
    "load_dotenv()\n",
    "langchain_api = os.getenv('LANGCHAIN_API_KEY')\n",
    "TAVILY_API_KEY = os.getenv('TAVILY_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'\n",
    "COHERE_API_KEY=os.getenv('COHERE_API_KEY')\n",
    "\n",
    "urls = [\n",
    "    \"https://lilianweng.github.io/posts/2023-06-23-agent/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-03-15-prompt-engineering/\",\n",
    "    \"https://lilianweng.github.io/posts/2023-10-25-adv-attack-llm/\",\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc99c3f1",
   "metadata": {},
   "source": [
    "### Index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "7e0c6892",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs = [WebBaseLoader(url).load() for url in urls]\n",
    "docs_list = [item for sublist in docs for item in sublist]\n",
    "\n",
    "embd = CohereEmbeddings(model=\"embed-multilingual-v3.0\")\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter.from_tiktoken_encoder(\n",
    "    chunk_size=512,chunk_overlap=0\n",
    ")\n",
    "splited_text = text_splitter.split_documents(docs_list)\n",
    "\n",
    "vectorspace = Chroma.from_documents(\n",
    "    embedding=embd,\n",
    "    documents=splited_text,\n",
    ")\n",
    "\n",
    "retriever = vectorspace.as_retriever()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "133faa25",
   "metadata": {},
   "source": [
    "### Router"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cde80aa0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class web_search(BaseModel):\n",
    "    \"\"\"\n",
    "    The internet. Use web_search for questions that are related to anything else than agents, prompt engineering, and adversarial attacks.\n",
    "    \"\"\"\n",
    "    query: str=Field(description=\"The query to use when searching the internet\")\n",
    "\n",
    "class vectorstore(BaseModel):\n",
    "    \"\"\"\n",
    "    A vectorstore containing documents related to agents, prompt engineering, and adversarial attacks. Use the vectorstore for questions on these topics.   \n",
    "    \"\"\"\n",
    "    query: str=Field(description= \"The query to use when searching the vectorstore\")\n",
    "\n",
    "\n",
    "preamble = \"\"\"You are an expert at routing a user question to a vectorstore or web search.\n",
    "The vectorstore contains documents related to agents, prompt engineering, and adversarial attacks.\n",
    "Use the vectorstore for questions on these topics. Otherwise, use web-search.\"\"\"\n",
    "\n",
    "llm = ChatCohere(model=\"command-a-03-2025\",temperature=0)\n",
    "structured_llm_router = llm.bind_tools(tools=[web_search,vectorstore],\n",
    "                                       preamble=preamble)\n",
    "\n",
    "route_prompt = ChatPromptTemplate(\n",
    "    [\n",
    "        ('user', \"{question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "question_router = route_prompt|structured_llm_router\n",
    "\n",
    "response = question_router.invoke(\n",
    "    {\"question\": \"Who will the Bears draft first in the NFL draft?\"}\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "2bf18d9e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'web_search'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.additional_kwargs['tool_calls'][0]['function']['name']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b9ef6e",
   "metadata": {},
   "source": [
    "### Retireval Grader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "dcb96596",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/envs/pytorch/lib/python3.12/site-packages/langchain_openai/chat_models/base.py:1900: UserWarning: Received a Pydantic BaseModel V1 schema. This is not supported by method=\"json_schema\". Please use method=\"function_calling\" or specify schema via JSON Schema or Pydantic V2 BaseModel. Overriding to method=\"function_calling\".\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "binary_score='no'\n"
     ]
    }
   ],
   "source": [
    "# class GradeDocuments(BaseModel):\n",
    "#     binary_score: Literal[\"yes\",\"no\"] = Field(\n",
    "#         description=\"Documents are relevant to the question: 'yes' or 'no'\"\n",
    "#     )\n",
    "\n",
    "# preamble = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n\n",
    "# If the document contains keyword(s) or semantic meaning related to the user question, grade it as relevant. \\n\n",
    "# Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "\n",
    "\n",
    "# llm = ChatCohere(model=\"command-a-03-2025\",temperature=0)\n",
    "# structure_llm_grader = llm.with_structured_output(GradeDocuments,preamble=preamble)\n",
    "# grader_prompt = ChatPromptTemplate.from_messages([\n",
    "#     ('human',\"Retrieved Document: \\n\\n{documents} \\n\\n User question: \\n\\n {question}\"),\n",
    "# ])\n",
    "class GradeDocuments(BaseModel):\n",
    "    binary_score : Literal[\"yes\",\"no\"] = Field(\n",
    "        description=\"Documents are relevant to the question, 'yes', or 'no'\"\n",
    "    )\n",
    "\n",
    "llm = ChatOpenAI(model='gpt-4o-mini', temperature=0)\n",
    "structured_llm_grader = llm.with_structured_output(GradeDocuments)\n",
    "\n",
    "system = \"\"\"You are a grader assessing relevance of a retrieved document to a user question. \\n \n",
    "    If the document contains keyword(s) or semantic meaning related to the question, grade it as relevant. \\n\n",
    "    Give a binary score 'yes' or 'no' score to indicate whether the document is relevant to the question.\"\"\"\n",
    "grader_prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\" , system),\n",
    "        (\"user\", \"Retrieved document: \\n\\n {document} \\n\\n User question: {question}\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "retrieval_grader_chain = grader_prompt|structured_llm_grader\n",
    "question = \"Who will the Bears draft first in the NFL draft?\"\n",
    "docs = retriever.get_relevant_documents(question)[0].page_content\n",
    "generation = retrieval_grader_chain.invoke({\"document\": docs, \"question\": question})\n",
    "print(generation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a62f7277",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
