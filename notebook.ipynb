{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "07224099",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import bs4\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from dotenv import load_dotenv\n",
    "from langchain_community.document_loaders import WebBaseLoader\n",
    "from langchain_community.vectorstores import Chroma\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "load_dotenv()\n",
    "langchain_api = os.getenv('LANGCHAIN_API_KEY')\n",
    "os.environ['LANGCHAIN_TRACING_V2'] = 'true'\n",
    "os.environ['LANGCHAIN_ENDPOINT'] = 'https://api.smith.langchain.com'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "65029e8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "loader = WebBaseLoader(\n",
    "    web_paths=(\"https://lilianweng.github.io/posts/2023-06-23-agent/\",),\n",
    "    bs_kwargs=dict(parse_only =bs4.SoupStrainer( class_=(\"post-content\", \"post-title\", \"post-header\" )))\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "f53f226c",
   "metadata": {},
   "outputs": [],
   "source": [
    "docs= loader.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "f71841bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=1000, chunk_overlap=200)\n",
    "splits = text_splitter.split_documents(docs)\n",
    "vectorstore = Chroma.from_documents(documents=splits, embedding=OpenAIEmbeddings())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "b736680c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys(['ids', 'embeddings', 'documents', 'uris', 'included', 'data', 'metadatas'])\n",
      "ID: 1af38bdd-bed6-4f35-83a1-404056b542cf\n",
      "Text: LLM Powered Autonomous Agents\n",
      "    \n",
      "Date: June 23, 2023  |  Estimated Reading Time: 31 min  |  Author: Lilian Weng\n",
      "\n",
      "\n",
      "Building agents with LLM (large language model) as its core controller is a cool con\n",
      "Meta: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "==================================================\n",
      "ID: c571a2ee-dc45-459e-8434-fe4fd265e369\n",
      "Text: Memory\n",
      "\n",
      "Short-term memory: I would consider all the in-context learning (See Prompt Engineering) as utilizing short-term memory of the model to learn.\n",
      "Long-term memory: This provides the agent with th\n",
      "Meta: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "==================================================\n",
      "ID: 4548f622-1661-4f88-9dec-40e1ebc846ea\n",
      "Text: Component One: Planning#\n",
      "A complicated task usually involves many steps. An agent needs to know what they are and plan ahead.\n",
      "Task Decomposition#\n",
      "Chain of thought (CoT; Wei et al. 2022) has become a s\n",
      "Meta: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "==================================================\n",
      "ID: 37d5b582-9c66-43e4-ac2b-fa9ed84bafe4\n",
      "Text: Task decomposition can be done (1) by LLM with simple prompting like \"Steps for XYZ.\\n1.\", \"What are the subgoals for achieving XYZ?\", (2) by using task-specific instructions; e.g. \"Write a story outl\n",
      "Meta: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "==================================================\n",
      "ID: c16995d5-7978-4977-a839-0cb9c7ff2532\n",
      "Text: Self-Reflection#\n",
      "Self-reflection is a vital aspect that allows autonomous agents to improve iteratively by refining past action decisions and correcting previous mistakes. It plays a crucial role in r\n",
      "Meta: {'source': 'https://lilianweng.github.io/posts/2023-06-23-agent/'}\n",
      "==================================================\n"
     ]
    }
   ],
   "source": [
    "out = vectorstore._collection.get(include=[\"documents\", \"metadatas\"])\n",
    "print(out.keys())\n",
    "\n",
    "for i in range(min(5,len(out['ids']))):\n",
    "    print(\"ID:\", out[\"ids\"][i])\n",
    "    print(\"Text:\", out[\"documents\"][i][:200])\n",
    "    print(\"Meta:\", out[\"metadatas\"][i])\n",
    "    print(\"=\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "d96de6a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "63"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorstore._collection.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6e4d1167",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "you are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\n",
      "Question: {question} \n",
      "Context: {context} \n",
      "Answer:\n"
     ]
    }
   ],
   "source": [
    "retriever = vectorstore.as_retriever()\n",
    "prompt = \"you are an assistant for question-answering tasks. Use the following pieces of retrieved context to answer the question. If you don't know the answer, just say that you don't know. Use three sentences maximum and keep the answer concise.\\nQuestion: {question} \\nContext: {context} \\nAnswer:\"\n",
    "print(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "1c586aa6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Task decomposition is a technique used to break down complex tasks into smaller and simpler steps. It involves transforming big tasks into multiple manageable tasks to enhance model performance. Different methods like Chain of Thought and Tree of Thoughts are used to decompose tasks and improve understanding of the model's thinking process.\""
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm = ChatOpenAI(model_name = 'gpt-3.5-turbo',temperature=0)\n",
    "def format_docs(docs):\n",
    "    return '\\n\\n'.join(doc.page_content for doc in docs)\n",
    "\n",
    "rag_chain = (\n",
    "    {\"context\": retriever | format_docs, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "rag_chain.invoke(\"What is Task Decomposition?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e75c9966",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
